Rollins College, CMS495 Computational Photography Project
The motivation behind this project was to use images to create scenes of interesting juxtapositions of impossible circumstances, such as a bird flying underwater, or a snowboarder riding the waves. The program takes two input images: a foreground and a background. The foreground object within the foreground image is extracted computationally. In order to achieve an accurate and automatic extraction computationally, the image is contoured. Each contour is bounded by a rectangle, the largest of which is identified to be the foreground object, and is extracted from the image using the Grab Cut algorithm. To help ensure accurate contouring, several measures were taken along the way.
The image was first quantized, thus reducing the number of colors and eliminating some of the variation that would yield skewed segmentation results. The image is then thresholded to segment it, and the result is de-noised and run through the Canny edge detection algorithm. The edge-detected image is used to identify the contours, which are then bounded by rectangles, from which the largest dimensions are used in the Grab Cut algorithm to finally extract the foreground. This yields an image containing only that foreground object. This image is converted to black and white, creating a binary mask. The mask can then to be applied to the input images, which are subsequently added together to generate the final composite image.
